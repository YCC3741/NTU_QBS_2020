{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pvoE1wS528vm"
      },
      "source": [
        "**To** make sure the code could be executed, please run it on Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "--c6eT-AsHr2"
      },
      "source": [
        "# Step 0. Set up Colab environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEe1sJr3uV2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDsGDRI6vCMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFyLK9kdvw0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp kaggle.json ~/.kaggle/ \n",
        "!kaggle competitions download -c ntu-qbs-assignment-2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn_Cdy8FAdgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/test_numeric.csv.zip -d /content/data\n",
        "!unzip /content/test_date.csv.zip -d /content/data\n",
        "!unzip /content/test_categorical.csv.zip -d /content/data\n",
        "!unzip /content/train_numeric.csv.zip -d /content/data\n",
        "!unzip /content/train_date.csv.zip -d /content/data\n",
        "!unzip /content/train_categorical.csv.zip -d /content/data\n",
        "!unzip /content/sample.csv.zip -d /content/data\n",
        "\n",
        "!rm /content/test_numeric.csv.zip\n",
        "!rm /content/test_date.csv.zip\n",
        "!rm /content/test_categorical.csv.zip\n",
        "!rm /content/train_numeric.csv.zip\n",
        "!rm /content/train_date.csv.zip\n",
        "!rm /content/train_categorical.csv.zip\n",
        "!rm /content/sample.csv.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCAZzyAQmZeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "8cOAc521slKf"
      },
      "outputs": [],
      "source": [
        "# Step 1. Set up Python environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp4jasY0v1ed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "import pandas as pd\n",
        "import numpy as np # linear algebra\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U_sQv5RKzP4L"
      },
      "source": [
        "# Step 2. Read data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WL6151yBzIw6"
      },
      "source": [
        "***Date data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDwS1wiPytqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_date = pd.read_csv('/content/data/train_date.csv').astype('float32')\n",
        "test_date = pd.read_csv('/content/data/test_date.csv').astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jrGHWUBooLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_date = train_date.drop(\"Id\", axis=1)\n",
        "test_date = test_date.drop(\"Id\", axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ughKmmPSs6ZF",
        "colab_type": "text"
      },
      "source": [
        "***Numerical data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpuUlxMNzSeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_numeric = pd.read_csv('/content/data/test_numeric.csv').astype('float32')\n",
        "train_numeric = pd.read_csv('/content/data/train_numeric.csv').astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsFm-GwXpBGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_numeric = train_numeric.drop(\"Id\", axis=1)\n",
        "test_numeric = test_numeric.drop(\"Id\", axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWOfdlfRt3mK",
        "colab_type": "text"
      },
      "source": [
        "***Reduce momerry***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ow-N0x6C8Cx",
        "colab_type": "text"
      },
      "source": [
        "A function to reduce the ram usage by assigning the type which uses the smallest ram."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8f_6b_1v-Mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_mem_usage(props):\n",
        "    start_mem_usg = props.memory_usage().sum() / 1024**2 \n",
        "    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
        "    NAlist = [] # Keeps track of columns that have missing values filled in. \n",
        "    for col in props.columns:\n",
        "        if props[col].dtype != object:  # Exclude strings\n",
        "            \n",
        "            # Print current column type\n",
        "            print(\"******************************\")\n",
        "            print(\"Column: \",col)\n",
        "            print(\"dtype before: \",props[col].dtype)\n",
        "            \n",
        "            # make variables for Int, max and min\n",
        "            IsInt = False\n",
        "            mx = props[col].max()\n",
        "            mn = props[col].min()\n",
        "            \n",
        "            # Integer does not support NA, therefore, NA needs to be filled\n",
        "            if not np.isfinite(props[col]).all(): \n",
        "                NAlist.append(col)\n",
        "                props[col].fillna(mn-1,inplace=True)  \n",
        "                   \n",
        "            # test if column can be converted to an integer\n",
        "            asint = props[col].fillna(0).astype(np.int64)\n",
        "            result = (props[col] - asint)\n",
        "            result = result.sum()\n",
        "            if result > -0.01 and result < 0.01:\n",
        "                IsInt = True\n",
        "\n",
        "            \n",
        "            # Make Integer/unsigned Integer datatypes\n",
        "            if IsInt:\n",
        "                if mn >= 0:\n",
        "                    if mx < 255:\n",
        "                        props[col] = props[col].astype(np.uint8)\n",
        "                    elif mx < 65535:\n",
        "                        props[col] = props[col].astype(np.uint16)\n",
        "                    elif mx < 4294967295:\n",
        "                        props[col] = props[col].astype(np.uint32)\n",
        "                    else:\n",
        "                        props[col] = props[col].astype(np.uint64)\n",
        "                else:\n",
        "                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
        "                        props[col] = props[col].astype(np.int8)\n",
        "                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
        "                        props[col] = props[col].astype(np.int16)\n",
        "                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
        "                        props[col] = props[col].astype(np.int32)\n",
        "                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
        "                        props[col] = props[col].astype(np.int64)    \n",
        "            \n",
        "            # Make float datatypes 32 bit\n",
        "            else:\n",
        "                props[col] = props[col].astype(np.float16)\n",
        "            \n",
        "            # Print new column type\n",
        "            print(\"dtype after: \",props[col].dtype)\n",
        "            print(\"******************************\")\n",
        "\n",
        "        else: #string case\n",
        "\n",
        "            # Print current column type\n",
        "            print(\"******************************\")\n",
        "            print(\"Column: \",col)\n",
        "            print(\"dtype before: \",props[col].dtype)\n",
        "\n",
        "            props[col] = props[col].astype('category')\n",
        "\n",
        "             # Print new column type\n",
        "            print(\"dtype after: \",props[col].dtype)\n",
        "            print(\"******************************\")\n",
        "\n",
        "\n",
        "    # Print final result\n",
        "    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
        "    mem_usg = props.memory_usage().sum() / 1024**2 \n",
        "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
        "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
        "\n",
        "    return props"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFgskduAzgU1",
        "colab_type": "text"
      },
      "source": [
        "***Categorical data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFHXq1-pzlfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import  numpy as np\n",
        "\n",
        "data = pd.read_csv(\"/content/data/train_categorical.csv\",chunksize=1)\n",
        "\n",
        "for df in data:\n",
        "    column_name = df.columns\n",
        "    break\n",
        "\n",
        "train_categorical = pd.read_csv(\"/content/data/train_categorical.csv\",usecols=column_name[0:141])[column_name[0:141]]\n",
        "train_categorical = reduce_mem_usage(train_categorical)\n",
        "\n",
        "for i in range(0,2000,400):\n",
        "    temp = pd.read_csv(\"/content/data/train_categorical.csv\", usecols=column_name[(141+i):(541+i)])[column_name[(141+i):(541+i)]]\n",
        "    train_categorical = pd.concat([train_categorical, reduce_mem_usage(temp)], axis=1, ignore_index=True)\n",
        "\n",
        "\n",
        "test_categorical = pd.read_csv(\"/content/data/test_categorical.csv\",usecols=column_name[0:141])[column_name[0:141]]\n",
        "test_categorical = reduce_mem_usage(test_categorical)\n",
        "\n",
        "for i in range(0,2000,400):\n",
        "    temp = pd.read_csv(\"/content/data/test_categorical.csv\", usecols=column_name[(141+i):(541+i)])[column_name[(141+i):(541+i)]]\n",
        "    test_categorical = pd.concat([test_categorical, reduce_mem_usage(temp)], axis=1, ignore_index=True)\n",
        "\n",
        "train_categorical.columns = column_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1SBbN0SXfbY",
        "colab_type": "text"
      },
      "source": [
        "# Step 3. EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SN9Ec5i-axjO",
        "colab_type": "text"
      },
      "source": [
        "### See if there are NA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM-oQ_1ophIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_categorical.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYLDtVzeXovO",
        "colab_type": "text"
      },
      "source": [
        "### The distribution of 1, 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KbBYoDkt3iv",
        "colab_type": "text"
      },
      "source": [
        "So we could lnow how to set weight class in the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqkdFySxXegT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y = train_numeric.loc[:,\"Response\"].astype(\"int16\")\n",
        "x_train_label_to_draw = pd.DataFrame(dict(traget=train_y))\n",
        "\n",
        "pic_0_1 = sns.catplot(x=\"traget\", y=\"traget\", data=x_train_label_to_draw, kind=\"bar\",\\\n",
        "                      height=4, aspect=1, estimator=lambda x: len(x) / len(x_train_label_to_draw) * 100)\n",
        "                      \n",
        "pic_0_1.set(ylabel=\"Percent\")\n",
        "pic_0_1.fig.suptitle(\"0 and 1 proportion\")\n",
        "\n",
        "print(\"0: {} %\".format( round(x_train_label_to_draw.traget.value_counts()[0] / len(x_train_label_to_draw), 4)* 100 ) )\n",
        "print(\"1: {} %\".format( round(x_train_label_to_draw.traget.value_counts()[1] / len(x_train_label_to_draw), 4)* 100 ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f75J9roSsw4b",
        "colab_type": "text"
      },
      "source": [
        "# Step 4. Feature engineer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udd3pbO0UNoh",
        "colab_type": "text"
      },
      "source": [
        "### Numeric\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKyuVkOEWElz",
        "colab_type": "text"
      },
      "source": [
        "***Use XGboost to find out the important columns***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6Y26hqGfoaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_importance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC-XDBUck8RO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = train_numeric.iloc[:,0:968]\n",
        "col_list = X.columns\n",
        "\n",
        "y = train_numeric.iloc[:,968]\n",
        "\n",
        "X = X.values\n",
        "y = np.nan_to_num(y)\n",
        "\n",
        "clf = XGBClassifier(base_score=0.005) # use model to find important columns\n",
        "clf.fit(X, y)\n",
        "\n",
        "# threshold for a manageable number of features\n",
        "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
        "plt.hist(clf.feature_importances_[clf.feature_importances_ > 0])\n",
        "fig.savefig(\"/content/output/xgboost_hist.png\") ## to see the important feature pic\n",
        "plt.close(fig)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20,50))\n",
        "plt.xlabel('xlabel', fontsize=18)\n",
        "plt.ylabel('ylabel', fontsize=18)\n",
        "plt.xticks(size=12)\n",
        "plt.yticks(size=12)\n",
        "myplt = plot_importance(clf, ax=ax)\n",
        "fig.savefig(\"/content/output/xgboost_importantfeatures.png\") ## to see the important feature pic\n",
        "plt.close(fig)\n",
        "\n",
        "important_indices = np.where(clf.feature_importances_ > 0.005)[0] ## to find out the important columns\n",
        "\n",
        "important_columns = [col for i, col in enumerate(col_list) if i in important_indices]  # converts important_indices to col names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4LMReB3N0q3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "important_columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n01oRcVOUeky",
        "colab_type": "text"
      },
      "source": [
        "***Normalise and Fill numeric NAN***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DqXE6wW3b6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "selected_train_numeric = train_numeric.loc[:,important_columns]\n",
        "selected_test_numeric = test_numeric.loc[:,important_columns]\n",
        "\n",
        "def normalise_and_fill(train_part, test_part):\n",
        "    mean_nu = np.nanmean(train_part, axis=0)\n",
        "    std_nu = np.nanstd(train_part, axis=0) \n",
        "    train_part = (train_part - mean_nu)/std_nu\n",
        "    test_part = (test_part - mean_nu)/std_nu\n",
        "\n",
        "    col_list = selected_test_numeric\n",
        "\n",
        "    select_to_dict = []\n",
        "    for (col, mean) in zip(col_list, mean_nu):\n",
        "        select_to_dict.append(col)\n",
        "        select_to_dict.append(mean)\n",
        "\n",
        "    it = iter(select_to_dict) \n",
        "    fill_na_dict = dict(zip(it, it)) \n",
        "\n",
        "    train_part = train_part.fillna(fill_na_dict)\n",
        "    test_part = test_part.fillna(fill_na_dict)\n",
        "\n",
        "    return train_part, test_part\n",
        "\n",
        "\n",
        "selected_train_numeric, selected_test_numeric = normalise_and_fill(selected_train_numeric, selected_test_numeric)\n",
        "\n",
        "print(selected_train_numeric)\n",
        "print(selected_test_numeric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlbtaJ6hU3wM",
        "colab_type": "text"
      },
      "source": [
        "### Date"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxkzzSTIDy6r",
        "colab_type": "text"
      },
      "source": [
        "***Drop similiar columns***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ECqHzIWD7YN",
        "colab_type": "text"
      },
      "source": [
        "I drop the similiar columns, because when training the model the similiar columns are redundant and could be harmful to the prediction because of the multicollinear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD1uIS8UIkLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getunique(df):\n",
        "    now_same_data = -1\n",
        "    uniqueColumnNames = []\n",
        "\n",
        "    uniqueColumnNames.append(df.columns.values[0])\n",
        "    \n",
        "    # Iterate over all the columns in dataframe\n",
        "    for x in range(df.shape[1]):\n",
        "        if (x >= now_same_data):\n",
        "            col = df.iloc[:, x]\n",
        "            for y in range(x + 1, df.shape[1]):\n",
        "                # Select column at yth index.\n",
        "                otherCol = df.iloc[:, y]\n",
        "                # Check if two columns at x  y index are equal\n",
        "                if (not col.equals(otherCol)):\n",
        "                    uniqueColumnNames.append(df.columns.values[y])\n",
        "                    now_same_data = y\n",
        "                    break\n",
        "\n",
        "    return uniqueColumnNames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKaF-9MtI5zh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uniqueColumnNames = getunique(train_date)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNIgUFs1MlqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(uniqueColumnNames))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dg3IZcibN7y",
        "colab_type": "text"
      },
      "source": [
        "***Fill NA in the Date***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aO7q1GgBNKlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "selected_train_date = train_date.loc[:, uniqueColumnNames].fillna(0)\n",
        "selected_test_date = test_date.loc[:, uniqueColumnNames].fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x6KKCrTNz7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = pd.concat([selected_train_numeric, selected_train_date],axis =1).to_numpy()\n",
        "test_x =  pd.concat([selected_test_numeric, selected_test_date],axis =1).to_numpy()\n",
        "train_y = train_numeric.loc[:,\"Response\"].astype(\"int16\")\n",
        "train_y = train_y.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1mbigTwSSZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "selected_train_date.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSwBKCdrYOw_",
        "colab_type": "text"
      },
      "source": [
        "# Step 5. K-Fold Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWtIYlQyI_56",
        "colab_type": "text"
      },
      "source": [
        "A function for building up the model, so that when we need to build the model, we don't need to do the redundant work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcOsAqOPYJyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models, layers, regularizers\n",
        "\n",
        "def build_model(): # a function to build model\n",
        "    model = models.Sequential()\n",
        "    \n",
        "    model.add(layers.Dense(80, activation=\"relu\", kernel_regularizer = regularizers.l2(0.001), input_shape=(len(train_x[0]),) ) )\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(40, activation=\"relu\", kernel_regularizer = regularizers.l2(0.001)))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(30, activation=\"relu\", kernel_regularizer = regularizers.l2(0.001)))\n",
        "    model.add(layers.Dense(25, activation=\"relu\", kernel_regularizer = regularizers.l2(0.001)))\n",
        "    model.add(layers.Dense(1, activation=\"sigmoid\", kernel_regularizer = regularizers.l1_l2(0.001)))\n",
        "\n",
        "    model.compile(optimizer= \"rmsprop\", loss= \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuHaKQypJRlX",
        "colab_type": "text"
      },
      "source": [
        "K-fold Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew7pOI2bYLMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"from sklearn.utils import class_weight\"\"\"\n",
        "\n",
        "num_portion = 3\n",
        "num_val_sameples = len(train_x) // num_portion\n",
        "num_epochs = 10\n",
        "\n",
        "# four lists to record loss, val_loss, acc, val_acc\n",
        "all_loss = []\n",
        "all_val_loss = []\n",
        "all_acc = []\n",
        "all_val_acc = []\n",
        "\n",
        "for i in range(num_portion): # go through every part of validation\n",
        "    print(\"processing fold {} ...\".format(i+1))\n",
        "\n",
        "    val_data = train_x[i*num_val_sameples : (i+1)*num_val_sameples]\n",
        "    val_label = train_y[i*num_val_sameples : (i+1)*num_val_sameples]\n",
        "    \n",
        "    prartial_x_train = np.concatenate( [ train_x[: i*num_val_sameples], train_x[(i+1)*num_val_sameples: ] ], axis=0)\n",
        "\n",
        "    prartial_x_train_label = np.concatenate( [ train_y[: i*num_val_sameples],\\\n",
        "                                                train_y[(i+1)*num_val_sameples: ] ], axis=0)\n",
        "    \n",
        "    model = build_model()\n",
        "    class_weights = {0:0.05, 1:10} # set class_weights, so we can avoid that the model tends to predict data as 0\n",
        "\n",
        "    history = model.fit(prartial_x_train, prartial_x_train_label, validation_data=(val_data, val_label), epochs=num_epochs,\\\n",
        "                        batch_size=1024, verbose=0, class_weight=class_weights)\n",
        "    ''', class_weight=class_weights'''\n",
        "\n",
        "    loss = history.history[\"loss\"]\n",
        "    val_loss = history.history[\"val_loss\"]\n",
        "    acc = history.history[\"accuracy\"]\n",
        "    val_acc = history.history[\"val_accuracy\"]\n",
        "    \n",
        "    all_loss.append(loss)\n",
        "    all_val_loss.append(val_loss)\n",
        "    all_acc.append(acc)\n",
        "    all_val_acc.append(val_acc)\n",
        "    \n",
        "    print()\n",
        "\n",
        "print(\"< ====== K-fold Validation ends ====== >\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HWzknQP1OZ1",
        "colab_type": "text"
      },
      "source": [
        "See the porformance and dicide the probability to transform probability into True or False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLb9ssjDDoEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "train_predict = model.predict(train_x)\n",
        "roc_auc_score(train_y, train_predict) ## to see the roc auc instead of auc, because there is extremely imbalanced"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nunwnZHXK0kO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_predict.min())\n",
        "print(train_predict.max())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JegPbrjsnfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "standard = (train_predict.max() + train_predict.min())/2\n",
        "standard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeFR-Mx_FiL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = np.zeros(len(train_predict))\n",
        "pred = pred.astype(str)\n",
        "\n",
        "for i, pred_y in enumerate(train_predict): # change the probability into 1 or 0\n",
        "    if(pred_y[0] > standard): \n",
        "        pred[i] = \"True\"\n",
        "    else:\n",
        "        pred[i] = \"False\"\n",
        "\n",
        "num = 0\n",
        "for i in pred:\n",
        "    if i == \"True\":\n",
        "        num += 1\n",
        "num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBUsHewM1iDb",
        "colab_type": "text"
      },
      "source": [
        "To see the loss and acurracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfLhByYgYTyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "average_all_loss = [ np.mean( [loss[i] for loss in all_loss] ) for i in range(num_epochs) ]\n",
        "average_all_val_loss = [ np.mean( [val_loss[i] for val_loss in all_val_loss] ) for i in range(num_epochs) ]\n",
        "average_all_acc = [ np.mean( [acc[i] for acc in all_acc] ) for i in range(num_epochs) ]\n",
        "average_all_val_acc = [ np.mean( [val_acc[i] for val_acc in all_val_acc] ) for i in range(num_epochs) ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bqQernWYWMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(range(len(average_all_loss)), average_all_loss, 'bo', label = \"training loss\")\n",
        "plt.plot(range(len(average_all_val_loss)), average_all_val_loss, 'b', color='orange', label = \"valiadtion loss\")\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbdKgkloYZGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.clf()\n",
        "plt.plot(range(len(average_all_acc)), average_all_acc, 'bo', label = \"training acc\")\n",
        "plt.plot(range(len(average_all_val_acc)), average_all_val_acc, 'b', color='orange', label = \"validation acc\")\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yrSP5BJi8Qk",
        "colab_type": "text"
      },
      "source": [
        "# Step 6. Build models to predict test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI6HUfPxBpSP",
        "colab_type": "text"
      },
      "source": [
        "Rebuild the model by using the hyper-parameters got from K-fold validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc5WXzmNgTBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_model = build_model()\n",
        "\n",
        "class_weights = {0:0.05, 1:10} # set class_weights, so we can avoid that the model tends to predict data as 0\n",
        "\n",
        "final_model.fit(train_x, train_y, epochs=5, batch_size=1024, verbose=0, class_weight=class_weights)\n",
        "\n",
        "answer = final_model.predict(test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d11wRd1xI0m8",
        "colab_type": "text"
      },
      "source": [
        "See the min, mean and max of prediciton"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNUt2VADAdk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaD8xii5E9zW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(answer.min())\n",
        "print(answer.max())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SIr7h3ZoYgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "standard = (answer.max() + answer.min())\n",
        "standard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg3huAM8B-Rr",
        "colab_type": "text"
      },
      "source": [
        "Tranforms the probabilities got from prediction into Boolean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wdlf-NpfjHLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = np.zeros(len(answer))\n",
        "output = output.astype(str)\n",
        "\n",
        "for i, pred_y in enumerate(answer): # change the probability into 1 or 0\n",
        "    if(pred_y[0] > standard): \n",
        "        output[i] = \"True\"\n",
        "    else:\n",
        "        output[i] = \"False\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe1hvpPgCsPr",
        "colab_type": "text"
      },
      "source": [
        "See how many prediction would be \"True\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtHDpnRw34lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num = 0\n",
        "for i in output:\n",
        "    if i == \"True\":\n",
        "        num += 1\n",
        "num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q2nhbVJGGq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9945hwU1Ixz",
        "colab_type": "text"
      },
      "source": [
        "# Step 7. Output the outcome to csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvZEOd-njIB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = pd.DataFrame(data=output, columns=[\"Response\"])\n",
        "\n",
        "sub_try = pd.read_csv('/content/data/sample.csv')  # read the ID of example output\n",
        "sub_try.Response = output # set its Target as what we get from the prediction\n",
        "\n",
        "sub_try.to_csv('/content/output/answer.csv', index = False) # output the outcome as csv document"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "hw2_raw.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}