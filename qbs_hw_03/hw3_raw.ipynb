{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw3_raw.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fPP8bmg_m6q",
        "colab_type": "code",
        "outputId": "0505d3a0-488a-4fa7-bcb2-9cd7878e5f25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZwJkkTbVWpr",
        "colab_type": "code",
        "outputId": "04ca609e-b8e3-4084-d8dc-4f9b5c17f64e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "from zipfile import ZipFile\n",
        "import pandas as pd\n",
        "import numpy as np # linear algebra\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.applications import DenseNet121\n",
        "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam, Nadam\n",
        "from keras import backend as K\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras import models"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AstSZV2DWhDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''!cp -r \"/content/gdrive/My Drive/hw3_data_raw\" \"/content/hw3_data_raw\"'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md5zgnWoVY6U",
        "colab_type": "code",
        "outputId": "ea50d246-695a-42fb-dbb1-f33ee199610a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "defect_df = pd.read_csv('/content/hw3_data_raw/train.csv')\n",
        "\n",
        "print(defect_df.shape)\n",
        "defect_df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4985, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>ClassId</th>\n",
              "      <th>EncodedPixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>18661 28 18863 82 19091 110 19347 110 19603 11...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>37607 3 37858 8 38108 14 38359 20 38610 25 388...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>131973 1 132228 4 132483 6 132738 8 132993 11 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>229501 11 229741 33 229981 55 230221 77 230468...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ImageId  ClassId                                      EncodedPixels\n",
              "0        1        1  29102 12 29346 24 29602 24 29858 24 30114 24 3...\n",
              "1        5        3  18661 28 18863 82 19091 110 19347 110 19603 11...\n",
              "2        6        1  37607 3 37858 8 38108 14 38359 20 38610 25 388...\n",
              "3        7        4  131973 1 132228 4 132483 6 132738 8 132993 11 ...\n",
              "4        8        3  229501 11 229741 33 229981 55 230221 77 230468..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NQKmskcVa5t",
        "colab_type": "code",
        "outputId": "f8efe5bd-5068-4cff-f663-959c0a620b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "defect_df_gp = defect_df.groupby(by='ImageId', axis=0).agg('sum').drop(\"ClassId\", axis=1)\n",
        "defect_df_gp.reset_index(inplace=True)\n",
        "defect_df_gp[\"allMissing\"] = 0\n",
        "\n",
        "train_name = sorted([int(name.split(\".\")[0]) for name in os.listdir('/content/hw3_data_raw/train_images')])\n",
        "defect_name = sorted(list(defect_df_gp[\"ImageId\"]))\n",
        "nondefect_name = sorted(list(set(train_name)-set(defect_name)))\n",
        "\n",
        "nondefect_df = pd.DataFrame(data={\"ImageId\": nondefect_name , \"allMissing\":1})\n",
        "\n",
        "train_df_gp = pd.concat([defect_df_gp, nondefect_df])\n",
        "train_df_gp = train_df_gp.sort_values(\"ImageId\")\n",
        "train_df_gp.reset_index(inplace=True)\n",
        "train_df_gp = train_df_gp.drop(\"index\", axis=1)\n",
        "train_df_gp[\"ImageId\"] = train_df_gp[\"ImageId\"].astype(\"str\")\n",
        "train_df_gp[\"ImageId\"] = train_df_gp[\"ImageId\"].apply(lambda x: \"{}.JPG\".format(x))\n",
        "train_df_gp"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>allMissing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.JPG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.JPG</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.JPG</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.JPG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.JPG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8793</th>\n",
              "      <td>12561.JPG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8794</th>\n",
              "      <td>12563.JPG</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8795</th>\n",
              "      <td>12564.JPG</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8796</th>\n",
              "      <td>12567.JPG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8797</th>\n",
              "      <td>12568.JPG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8798 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        ImageId  allMissing\n",
              "0         1.JPG           0\n",
              "1         2.JPG           1\n",
              "2         3.JPG           1\n",
              "3         5.JPG           0\n",
              "4         6.JPG           0\n",
              "...         ...         ...\n",
              "8793  12561.JPG           0\n",
              "8794  12563.JPG           1\n",
              "8795  12564.JPG           1\n",
              "8796  12567.JPG           0\n",
              "8797  12568.JPG           0\n",
              "\n",
              "[8798 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBJt68-MVdCN",
        "colab_type": "code",
        "outputId": "16a00c6a-cf84-4972-f9a8-dfc84517f23f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "defect_df_gp"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>allMissing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4677</th>\n",
              "      <td>12558</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4678</th>\n",
              "      <td>12559</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4679</th>\n",
              "      <td>12561</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4680</th>\n",
              "      <td>12567</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4681</th>\n",
              "      <td>12568</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4682 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      ImageId  allMissing\n",
              "0           1           0\n",
              "1           5           0\n",
              "2           6           0\n",
              "3           7           0\n",
              "4           8           0\n",
              "...       ...         ...\n",
              "4677    12558           0\n",
              "4678    12559           0\n",
              "4679    12561           0\n",
              "4680    12567           0\n",
              "4681    12568           0\n",
              "\n",
              "[4682 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3U6XjzeVfxt",
        "colab_type": "code",
        "outputId": "42e12d41-396a-46e0-94f2-052433cc6962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "test_name = sorted([int(name.split(\".\")[0]) for name in os.listdir('/content/hw3_data_raw/test_images')])\n",
        "\n",
        "test_df_gp = pd.DataFrame(data={\"ImageId\": test_name})\n",
        "test_df_gp[\"ImageId\"] = test_df_gp[\"ImageId\"].astype(\"str\")\n",
        "test_df_gp[\"ImageId\"] = test_df_gp[\"ImageId\"].apply(lambda x: \"{}.JPG\".format(x))\n",
        "test_df_gp"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.JPG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10.JPG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11.JPG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15.JPG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.JPG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3765</th>\n",
              "      <td>12555.JPG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3766</th>\n",
              "      <td>12560.JPG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3767</th>\n",
              "      <td>12562.JPG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3768</th>\n",
              "      <td>12565.JPG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3769</th>\n",
              "      <td>12566.JPG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3770 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        ImageId\n",
              "0         4.JPG\n",
              "1        10.JPG\n",
              "2        11.JPG\n",
              "3        15.JPG\n",
              "4        17.JPG\n",
              "...         ...\n",
              "3765  12555.JPG\n",
              "3766  12560.JPG\n",
              "3767  12562.JPG\n",
              "3768  12565.JPG\n",
              "3769  12566.JPG\n",
              "\n",
              "[3770 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q65vwxsLVgN2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b9c96c26-fa46-445f-ea35-add117392810"
      },
      "source": [
        "\"\"\"remove_model = load_model('/content/hw3_data_raw/model_predict_no_defect.h5')\n",
        "remove_model.summary()\"\"\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"remove_model = load_model('/content/hw3_data_raw/model_predict_no_defect.h5')\\nremove_model.summary()\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ2rmrfhgJn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    densenet = DenseNet121(\n",
        "        include_top=False,\n",
        "        input_shape=(256,256,3),\n",
        "        weights='/content/hw3_data_raw/DenseNet-BC-121-32-no-top.h5'\n",
        "    )\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(densenet)\n",
        "    model.add(layers.GlobalAveragePooling2D())\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(512, activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=Nadam(),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Euj_HlJmgRQE",
        "colab_type": "code",
        "outputId": "ce8a8d0d-db52-4c08-c017-c0e9b5fe31eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        }
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "densenet121 (Model)          (None, 8, 8, 1024)        7037504   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 7,568,961\n",
            "Trainable params: 7,482,241\n",
            "Non-trainable params: 86,720\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL-U6h2HfUk6",
        "colab_type": "code",
        "outputId": "2164dae2-ffd7-464c-dce3-405cd0f9a8fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "def create_datagen():\n",
        "    return ImageDataGenerator(\n",
        "        rescale=1/255.,\n",
        "        validation_split=0.15,\n",
        "\n",
        "        rotation_range=10,\n",
        "        height_shift_range=0.1,\n",
        "        width_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        zoom_range=0.1,\n",
        "        fill_mode='constant',\n",
        "        cval=0.\n",
        "    )\n",
        "\n",
        "def create_flow(datagen, subset):\n",
        "    return datagen.flow_from_dataframe(\n",
        "        train_df_gp, \n",
        "        directory='/content/hw3_data_raw/train_images',\n",
        "        x_col='ImageId', \n",
        "        y_col='allMissing', \n",
        "        class_mode=\"raw\",\n",
        "        target_size=(256, 256),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        subset=subset\n",
        "    )\n",
        "\n",
        "# Using original generator\n",
        "data_generator = create_datagen()\n",
        "train_gen = create_flow(data_generator, 'training')\n",
        "val_gen = create_flow(data_generator, 'validation')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7479 validated image filenames.\n",
            "Found 1319 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pzCV6mlgvkI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a386add-5911-44e6-8f4c-2ee2f3232223"
      },
      "source": [
        "total_steps = train_df_gp.shape[0] / BATCH_SIZE\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    '/content/genre_train_model.h5', \n",
        "    monitor='val_accuracy', \n",
        "    verbose=1, \n",
        "    save_best_only=True, \n",
        "    save_weights_only=False,\n",
        "    mode='auto'\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    min_lr=1e-6\n",
        ")\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_gen,\n",
        "    steps_per_epoch=total_steps * 0.85,\n",
        "    validation_data=val_gen,\n",
        "    validation_steps=total_steps * 0.15,\n",
        "    epochs=40,\n",
        "    callbacks=[checkpoint, reduce_lr]\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "234/233 [==============================] - 569s 2s/step - loss: 0.3623 - accuracy: 0.8358 - val_loss: 1.0964 - val_accuracy: 0.7528\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.75284, saving model to /content/genre_train_model.h5\n",
            "Epoch 2/40\n",
            "234/233 [==============================] - 494s 2s/step - loss: 0.3351 - accuracy: 0.8513 - val_loss: 0.0542 - val_accuracy: 0.7915\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.75284 to 0.79151, saving model to /content/genre_train_model.h5\n",
            "Epoch 3/40\n",
            "234/233 [==============================] - 493s 2s/step - loss: 0.3299 - accuracy: 0.8543 - val_loss: 1.6773 - val_accuracy: 0.6187\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.79151\n",
            "Epoch 4/40\n",
            "234/233 [==============================] - 493s 2s/step - loss: 0.3043 - accuracy: 0.8671 - val_loss: 0.8855 - val_accuracy: 0.6247\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.79151\n",
            "Epoch 5/40\n",
            "234/233 [==============================] - 492s 2s/step - loss: 0.2936 - accuracy: 0.8708 - val_loss: 1.4312 - val_accuracy: 0.5398\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.79151\n",
            "Epoch 6/40\n",
            "234/233 [==============================] - 493s 2s/step - loss: 0.2814 - accuracy: 0.8837 - val_loss: 0.5431 - val_accuracy: 0.7847\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.79151\n",
            "Epoch 7/40\n",
            "234/233 [==============================] - 494s 2s/step - loss: 0.2774 - accuracy: 0.8833 - val_loss: 11.4472 - val_accuracy: 0.4822\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.79151\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 8/40\n",
            "234/233 [==============================] - 495s 2s/step - loss: 0.2253 - accuracy: 0.9057 - val_loss: 0.0966 - val_accuracy: 0.9030\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.79151 to 0.90296, saving model to /content/genre_train_model.h5\n",
            "Epoch 9/40\n",
            "234/233 [==============================] - 494s 2s/step - loss: 0.2171 - accuracy: 0.9110 - val_loss: 1.3653 - val_accuracy: 0.7324\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.90296\n",
            "Epoch 10/40\n",
            "234/233 [==============================] - 495s 2s/step - loss: 0.2091 - accuracy: 0.9170 - val_loss: 0.3401 - val_accuracy: 0.8848\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.90296\n",
            "Epoch 11/40\n",
            "234/233 [==============================] - 494s 2s/step - loss: 0.2107 - accuracy: 0.9126 - val_loss: 0.5308 - val_accuracy: 0.9083\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.90296 to 0.90826, saving model to /content/genre_train_model.h5\n",
            "Epoch 12/40\n",
            "234/233 [==============================] - 494s 2s/step - loss: 0.1995 - accuracy: 0.9216 - val_loss: 0.2421 - val_accuracy: 0.8400\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.90826\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
            "Epoch 13/40\n",
            "234/233 [==============================] - 493s 2s/step - loss: 0.1975 - accuracy: 0.9212 - val_loss: 0.1021 - val_accuracy: 0.9212\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.90826 to 0.92115, saving model to /content/genre_train_model.h5\n",
            "Epoch 14/40\n",
            "234/233 [==============================] - 493s 2s/step - loss: 0.1917 - accuracy: 0.9224 - val_loss: 0.7512 - val_accuracy: 0.9181\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.92115\n",
            "Epoch 15/40\n",
            "234/233 [==============================] - 493s 2s/step - loss: 0.1944 - accuracy: 0.9231 - val_loss: 0.0295 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.92115 to 0.93101, saving model to /content/genre_train_model.h5\n",
            "Epoch 16/40\n",
            "234/233 [==============================] - 493s 2s/step - loss: 0.1897 - accuracy: 0.9249 - val_loss: 0.3204 - val_accuracy: 0.9348\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.93101 to 0.93480, saving model to /content/genre_train_model.h5\n",
            "Epoch 17/40\n",
            "234/233 [==============================] - 492s 2s/step - loss: 0.2052 - accuracy: 0.9186 - val_loss: 0.2283 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.93480\n",
            "Epoch 18/40\n",
            "234/233 [==============================] - 493s 2s/step - loss: 0.1919 - accuracy: 0.9218 - val_loss: 0.6810 - val_accuracy: 0.9158\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.93480\n",
            "Epoch 19/40\n",
            "234/233 [==============================] - 492s 2s/step - loss: 0.1938 - accuracy: 0.9247 - val_loss: 0.0177 - val_accuracy: 0.9318\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.93480\n",
            "Epoch 20/40\n",
            "234/233 [==============================] - 492s 2s/step - loss: 0.1937 - accuracy: 0.9208 - val_loss: 0.2551 - val_accuracy: 0.9333\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.93480\n",
            "Epoch 21/40\n",
            "234/233 [==============================] - 492s 2s/step - loss: 0.1945 - accuracy: 0.9239 - val_loss: 0.0115 - val_accuracy: 0.9265\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.93480\n",
            "Epoch 22/40\n",
            "234/233 [==============================] - 493s 2s/step - loss: 0.1955 - accuracy: 0.9224 - val_loss: 0.0698 - val_accuracy: 0.9090\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.93480\n",
            "Epoch 23/40\n",
            "234/233 [==============================] - 492s 2s/step - loss: 0.1895 - accuracy: 0.9263 - val_loss: 0.0452 - val_accuracy: 0.9219\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.93480\n",
            "Epoch 24/40\n",
            "234/233 [==============================] - 493s 2s/step - loss: 0.1838 - accuracy: 0.9278 - val_loss: 0.0253 - val_accuracy: 0.9318\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.93480\n",
            "Epoch 25/40\n",
            "234/233 [==============================] - 492s 2s/step - loss: 0.1896 - accuracy: 0.9243 - val_loss: 0.0074 - val_accuracy: 0.9318\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.93480\n",
            "Epoch 26/40\n",
            "234/233 [==============================] - 492s 2s/step - loss: 0.1876 - accuracy: 0.9277 - val_loss: 0.0244 - val_accuracy: 0.9249\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.93480\n",
            "Epoch 27/40\n",
            "234/233 [==============================] - 493s 2s/step - loss: 0.1908 - accuracy: 0.9239 - val_loss: 0.0400 - val_accuracy: 0.9295\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.93480\n",
            "Epoch 28/40\n",
            "234/233 [==============================] - 493s 2s/step - loss: 0.1883 - accuracy: 0.9243 - val_loss: 0.3578 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.93480\n",
            "Epoch 29/40\n",
            "234/233 [==============================] - 491s 2s/step - loss: 0.1847 - accuracy: 0.9266 - val_loss: 0.0323 - val_accuracy: 0.9318\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.93480\n",
            "Epoch 30/40\n",
            "234/233 [==============================] - 492s 2s/step - loss: 0.1904 - accuracy: 0.9203 - val_loss: 0.0625 - val_accuracy: 0.9340\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.93480\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.0000001313746906e-06.\n",
            "Epoch 31/40\n",
            "234/233 [==============================] - 492s 2s/step - loss: 0.1919 - accuracy: 0.9242 - val_loss: 0.6404 - val_accuracy: 0.9295\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.93480\n",
            "Epoch 32/40\n",
            "234/233 [==============================] - 492s 2s/step - loss: 0.1906 - accuracy: 0.9224 - val_loss: 0.0465 - val_accuracy: 0.9249\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.93480\n",
            "Epoch 33/40\n",
            "234/233 [==============================] - 493s 2s/step - loss: 0.1802 - accuracy: 0.9277 - val_loss: 0.0213 - val_accuracy: 0.9287\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.93480\n",
            "Epoch 34/40\n",
            "234/233 [==============================] - 493s 2s/step - loss: 0.1832 - accuracy: 0.9307 - val_loss: 0.1137 - val_accuracy: 0.9272\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.93480\n",
            "Epoch 35/40\n",
            "234/233 [==============================] - 492s 2s/step - loss: 0.1766 - accuracy: 0.9291 - val_loss: 0.0191 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.93480\n",
            "\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "Epoch 36/40\n",
            "234/233 [==============================] - 493s 2s/step - loss: 0.1912 - accuracy: 0.9237 - val_loss: 0.2458 - val_accuracy: 0.9318\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.93480\n",
            "Epoch 37/40\n",
            "234/233 [==============================] - 493s 2s/step - loss: 0.1804 - accuracy: 0.9295 - val_loss: 0.0609 - val_accuracy: 0.9333\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.93480\n",
            "Epoch 38/40\n",
            "234/233 [==============================] - 493s 2s/step - loss: 0.1955 - accuracy: 0.9237 - val_loss: 0.0409 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.93480\n",
            "Epoch 39/40\n",
            "234/233 [==============================] - 493s 2s/step - loss: 0.1851 - accuracy: 0.9282 - val_loss: 0.0387 - val_accuracy: 0.9287\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.93480\n",
            "Epoch 40/40\n",
            "234/233 [==============================] - 493s 2s/step - loss: 0.1900 - accuracy: 0.9211 - val_loss: 0.0599 - val_accuracy: 0.9310\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.93480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJRlmdbTg0Tp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "7e21c8e9-ccc6-4f6a-a0d9-6bdd9082b8dc"
      },
      "source": [
        "history_df = pd.DataFrame(history.history)\n",
        "history_df[['loss', 'val_loss']].plot()\n",
        "history_df[['accuracy', 'val_accuracy']].plot()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f04431fee80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfvtWDpLVnQw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "3537fd1d-c9a4-4628-ca2f-a492493c79cd"
      },
      "source": [
        "remove_model = model \n",
        "BATCH_SIZE = 50\n",
        "\n",
        "def create_test_gen():\n",
        "    return ImageDataGenerator(rescale=1/255.).flow_from_dataframe(\n",
        "        test_df_gp,\n",
        "        directory='/content/hw3_data_raw/test_images',\n",
        "        x_col='ImageId',\n",
        "        class_mode=None,\n",
        "        target_size=(256, 256),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "test_gen = create_test_gen()\n",
        "\n",
        "remove_model.load_weights('/content/genre_train_model.h5')\n",
        "\n",
        "test_nondefect_pred = remove_model.predict_generator(\n",
        "    test_gen,\n",
        "    steps=len(test_gen),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "test_df_gp['allMissing'] = test_nondefect_pred\n",
        "test_df_gp.head()\n",
        "print(test_df_gp.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3770 validated image filenames.\n",
            "76/76 [==============================] - 68s 891ms/step\n",
            "(3770, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDbFT6SJYHPX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c83ec474-c1df-4e6f-84c9-3d74affa7288"
      },
      "source": [
        "print(test_df_gp['allMissing'].mean())\n",
        "print(test_df_gp['allMissing'].min())\n",
        "print(test_df_gp['allMissing'].max())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5857325792312622\n",
            "6.150827847051232e-09\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV3_J3CBVnxC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "c5ae15e8-7136-4d6d-827d-11a6503bda57"
      },
      "source": [
        "test_defect_df = test_df_gp[test_df_gp['allMissing'] < 0.5] #>0.5 means no defect\n",
        "\n",
        "test_defect_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(test_defect_df.shape)\n",
        "test_defect_df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1563, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>allMissing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23.JPG</td>\n",
              "      <td>2.177453e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31.JPG</td>\n",
              "      <td>2.592341e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>52.JPG</td>\n",
              "      <td>2.273133e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55.JPG</td>\n",
              "      <td>2.961169e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>70.JPG</td>\n",
              "      <td>1.112970e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  ImageId    allMissing\n",
              "0  23.JPG  2.177453e-01\n",
              "1  31.JPG  2.592341e-07\n",
              "2  52.JPG  2.273133e-02\n",
              "3  55.JPG  2.961169e-01\n",
              "4  70.JPG  1.112970e-01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7k6KJNbVrYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mask2rle(img):\n",
        "    '''\n",
        "    img: numpy array, 1 - mask, 0 - background\n",
        "    Returns run length as string formated\n",
        "    '''\n",
        "    pixels= img.T.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "\n",
        "def build_rles(masks):\n",
        "    width, height, depth = masks.shape\n",
        "    \n",
        "    rles = [mask2rle(masks[:, :, i])\n",
        "            for i in range(depth)]\n",
        "    \n",
        "    return rles\n",
        "\n",
        "\n",
        "\"\"\"\"\"\"\n",
        "\n",
        "\n",
        "def rle2mask(rle, input_shape):\n",
        "    width, height = input_shape[:2]\n",
        "    \n",
        "    mask= np.zeros( width*height ).astype(np.uint8)\n",
        "    \n",
        "    array = np.asarray([int(x) for x in rle.split()])\n",
        "    starts = array[0::2]\n",
        "    lengths = array[1::2]\n",
        "\n",
        "    current_position = 0\n",
        "    for index, start in enumerate(starts):\n",
        "        mask[int(start):int(start+lengths[index])] = 1\n",
        "        current_position += lengths[index]\n",
        "        \n",
        "    return mask.reshape(height, width).T\n",
        "\n",
        "\n",
        "def build_masks(rles, input_shape):\n",
        "    depth = 4\n",
        "    masks = np.zeros((*input_shape, depth))\n",
        "    \n",
        "    for i, rle in enumerate(rles):\n",
        "        if (rle != 0):\n",
        "            masks[:, :, i] = rle2mask(rle, input_shape)\n",
        "\n",
        "    return masks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxmuSl1XVtRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, base_path, IDs, target_df=None, mode='fit',\n",
        "                 batch_size=32, dim=(256, 1600), n_channels=1,\n",
        "                 n_classes=4, random_state=2020, shuffle=True):\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.mode = mode\n",
        "        self.IDs = IDs\n",
        "        self.base_path = base_path\n",
        "        self.target_df = target_df\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.random_state = random_state\n",
        "        \n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size : (index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        IDs_batch = [self.IDs[k] for k in indexes]\n",
        "        \n",
        "        X = self.__generate_X(IDs_batch)\n",
        "        \n",
        "        if self.mode == 'fit':\n",
        "            y = self.__generate_y(IDs_batch)\n",
        "            return X, y\n",
        "        \n",
        "        elif self.mode == 'predict':\n",
        "            return X\n",
        "\n",
        "        else:\n",
        "            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.seed(self.random_state)\n",
        "            np.random.shuffle(self.indexes)\n",
        "    \n",
        "    def __generate_X(self, IDs_batch):\n",
        "        'Generates data containing batch_size samples'\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        \n",
        "        # Generate data\n",
        "        for i, ID in enumerate(IDs_batch):\n",
        "            im_name = str(ID)+\".JPG\"\n",
        "            img_path = f\"{self.base_path}/{im_name}\"\n",
        "            img = self.__load_grayscale(img_path)\n",
        "            \n",
        "            # Store samples\n",
        "            X[i,] = img\n",
        "\n",
        "        return X\n",
        "    \n",
        "    def __generate_y(self, IDs_batch):\n",
        "        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n",
        "        \n",
        "        for i, ID in enumerate(IDs_batch):\n",
        "            im_name = ID\n",
        "            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n",
        "            im_id = image_df['ClassId'].values\n",
        "            rles = image_df['EncodedPixels'].values\n",
        "\n",
        "            defect_list = [0,0,0,0]\n",
        "            for num, encode in zip(im_id, rles):\n",
        "                if type(encode) is str:\n",
        "                    defect_list[num-1] = encode\n",
        "\n",
        "            masks = build_masks(defect_list, input_shape=self.dim)\n",
        "            \n",
        "            y[i, ] = masks\n",
        "\n",
        "        return y\n",
        "    \n",
        "    def __load_grayscale(self, img_path):\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = img.astype(np.float32) / 255.\n",
        "        img = np.expand_dims(img, axis=-1)\n",
        "\n",
        "        return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWCWAH0QV1lq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "2b8ebf1f-766a-410e-e6f6-7728c0ec1352"
      },
      "source": [
        "defect_df.dtypes"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageId           int64\n",
              "ClassId           int64\n",
              "EncodedPixels    object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hChirMz4V3AR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "\n",
        "genre_model = load_model(\n",
        "                        \"/content/hw3_data_raw/model_for_genre.h5\",\n",
        "                        custom_objects={'dice_coef': dice_coef})\n",
        "\n",
        "\n",
        "genre_model.trainable = True\n",
        "set_weight = False\n",
        "for i, layer in enumerate(genre_model.layers):\n",
        "    if(1):#3 6 9 12 15 17 19 23 \"27\" 31 35\n",
        "        set_weight = True\n",
        "\n",
        "    if set_weight:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "genre_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHhqGX1kV4Zd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b39cef0-7ebc-4b98-c7a5-310a0eb3d62a"
      },
      "source": [
        "genre_model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 256, 1600, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 256, 1600, 8) 80          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 256, 1600, 8) 584         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 128, 800, 8)  0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 128, 800, 16) 1168        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 128, 800, 16) 2320        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 64, 400, 16)  0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 64, 400, 32)  4640        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 64, 400, 32)  9248        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 32, 200, 32)  0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 200, 64)  18496       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 200, 64)  36928       conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 16, 100, 64)  0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 100, 64)  36928       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 100, 64)  36928       conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 8, 50, 64)    0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 8, 50, 128)   73856       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 8, 50, 128)   147584      conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 16, 100, 64)  32832       conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 16, 100, 128) 0           conv2d_transpose_1[0][0]         \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 100, 64)  73792       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 100, 64)  36928       conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 32, 200, 32)  8224        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 200, 96)  0           conv2d_transpose_2[0][0]         \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 200, 32)  27680       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 200, 32)  9248        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 64, 400, 32)  4128        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 64, 400, 64)  0           conv2d_transpose_3[0][0]         \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 64, 400, 32)  18464       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 64, 400, 32)  9248        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 128, 800, 16) 2064        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 128, 800, 32) 0           conv2d_transpose_4[0][0]         \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 128, 800, 16) 4624        concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 128, 800, 16) 2320        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 256, 1600, 8) 520         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 256, 1600, 16 0           conv2d_transpose_5[0][0]         \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 256, 1600, 8) 1160        concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 256, 1600, 8) 584         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 256, 1600, 4) 36          conv2d_22[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 600,612\n",
            "Trainable params: 600,612\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YfgVxfoV4zM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 25\n",
        "\n",
        "train_id, val_id = train_test_split(\n",
        "    defect_df_gp[\"ImageId\"].tolist(),  # name for imageid\n",
        "    random_state=2020, \n",
        "    test_size=0.1\n",
        ")\n",
        "\n",
        "train_generator = DataGenerator(\n",
        "    base_path='/content/hw3_data_raw/train_images',\n",
        "    IDs = train_id,\n",
        "    target_df=defect_df,\n",
        "    batch_size=BATCH_SIZE, \n",
        "    n_classes=4\n",
        ")\n",
        "\n",
        "val_generator = DataGenerator(\n",
        "    base_path='/content/hw3_data_raw/train_images',\n",
        "    IDs = val_id, \n",
        "    target_df=defect_df,\n",
        "    batch_size=BATCH_SIZE, \n",
        "    n_classes=4\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5Mvt3ohV6Xf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    '/content/outcome_model.h5', \n",
        "    monitor='val_loss', \n",
        "    verbose=1, \n",
        "    save_best_only=True, \n",
        "    save_weights_only=False,\n",
        "    mode='auto'\n",
        ")\n",
        "\n",
        "history = genre_model.fit_generator(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    use_multiprocessing=1,\n",
        "    workers=1,\n",
        "    epochs=20,\n",
        "    callbacks=[checkpoint]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkx1VNr5V_aq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_df = pd.DataFrame(history.history)\n",
        "history_df[['loss', 'val_loss']].plot()\n",
        "history_df[['dice_coef', 'val_dice_coef']].plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xfL1Wbfr1lU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_defect_df[\"ImageId\"] = test_defect_df[\"ImageId\"].apply(lambda x: int(x.split(\".\")[0]))\n",
        "test_defect_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33lYtb-kmsa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sub = test_defect_df.copy().drop(\"allMissing\", axis=1)\n",
        "test_sub = test_sub.loc[test_sub.index.repeat(4)]\n",
        "test_sub[\"ClassId\"] = [ ((i%4)+1) for i in range(len(test_sub))]\n",
        "test_sub.reset_index(drop=True, inplace=True)\n",
        "test_sub[\"EncodedPixels\"] = np.nan\n",
        "test_sub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIhPyBL7V75x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "genre_model.load_weights(\"/content/outcome_model.h5\")\n",
        "\n",
        "test_df = []\n",
        "whole_test_id_list = test_defect_df[\"ImageId\"].tolist()\n",
        "\n",
        "for i in range(0, test_defect_df.shape[0], 300):\n",
        "    batch_id = whole_test_id_list[i : min(test_defect_df.shape[0], i + 300)]\n",
        "    \n",
        "    test_generator = DataGenerator(\n",
        "                IDs = batch_id,\n",
        "                target_df = test_sub,\n",
        "                base_path='/content/hw3_data_raw/test_images',\n",
        "                mode='predict',\n",
        "                batch_size=1,\n",
        "                n_classes=4,\n",
        "                shuffle=False,   \n",
        "    )\n",
        "    \n",
        "    batch_pred_masks = genre_model.predict_generator(\n",
        "        test_generator, \n",
        "        workers=1,\n",
        "        verbose=1,\n",
        "        use_multiprocessing=False\n",
        "    )\n",
        "    \n",
        "    for j, b in tqdm(enumerate(batch_id)):\n",
        "        image_df = test_sub[test_sub['ImageId'] == b].copy()\n",
        "        \n",
        "        pred_masks = batch_pred_masks[j, ].round().astype(int)\n",
        "        pred_rles = build_rles(pred_masks)\n",
        "        \n",
        "        image_df['EncodedPixels'] = pred_rles\n",
        "        test_df.append(image_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhuXm07Yvdny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.concat(test_df)\n",
        "test_withvalue_df = test_df[test_df['EncodedPixels'] != \"\"]\n",
        "print(test_withvalue_df.shape)\n",
        "test_withvalue_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fALi-qxyyg4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_withvalue_df.to_csv('Submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}